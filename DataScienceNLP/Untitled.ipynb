{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised NLP on /r/datascience Comments\n",
    "\n",
    "This is a notebook for performing unsupervised NLP on the comments from the datascience subreddit \"Weekly Entering & Transitioning Thread\"\n",
    "\n",
    "The most current one being:\n",
    "https://www.reddit.com/r/datascience/comments/m4u0uu/weekly_entering_transitioning_thread_14_mar_2021/\n",
    "\n",
    "This notebook covers all steps of analysis:\n",
    "1. Data Scraping\n",
    "1. Data Cleaning\n",
    "1. Feature Engineering\n",
    "1. Modelling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import praw\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping\n",
    "\n",
    "To collect the comments will make use of the reddit praw API, which allows us to perform simple (but adequate) queries and collect posts and comments in a useful object oriented format!\n",
    "\n",
    "As a note, I store reddit IDs and Sectets in a separate yaml file, you will have to make your own if you plan to copy any code snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = open(\"/Users/harry/scrapeReddit/reddit_keys.yml\")\n",
    "parsed_yaml = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "reddit = praw.Reddit(client_id=parsed_yaml[\"client_id\"],                                                                                                                                                                                          \n",
    "                     client_secret=parsed_yaml[\"client_secret\"],                                                                                                                                                                       \n",
    "                     user_agent=parsed_yaml[\"user_agent\"],                                                                                                                                                                                            \n",
    "                     username=parsed_yaml[\"username\"],                                                                                                                                                                                      \n",
    "                     password=parsed_yaml[\"password\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search the datascience subreddit for posts with both \"weekly\" and \"thread\" in the title, and to only keep posts written by the authors \"datascience-bot\" and \"AutoModerator\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_AUTHORS = [\"datascience-bot\", \"AutoModerator\"]\n",
    "all_submissions = []\n",
    "for submission in reddit.subreddit(\"datascience\").search(\"weekly+thread\", limit=20):\n",
    "    if submission.author not in ALLOWED_AUTHORS:\n",
    "        continue\n",
    "    all_submissions.append(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to parse through all comments in the thread, saving for each comment: the id, url, thread name (a manually parsed string for keeping track), text body, username, comment depth, number of upvotes and number of replies.\n",
    "\n",
    "Number of replies has a little extra work, ensuring to only count replies that aren't from \"datascience-bot\" or \"AutoModerator\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = []\n",
    "\n",
    "for submission in all_submissions:\n",
    "\n",
    "    submission.comments.replace_more(limit=None)\n",
    "\n",
    "    thread_name = submission.title.split(\"|\")[-1]\n",
    "    thread_name = \"\".join(thread_name.split())\n",
    "\n",
    "    for comment in submission.comments.list():\n",
    "\n",
    "        comment_dict = {}\n",
    "        comment_dict[\"id\"] = comment.id\n",
    "        comment_dict[\"url\"] = \"reddit.com{}\".format(comment.permalink)\n",
    "        comment_dict[\"thread\"] = thread_name\n",
    "        comment_dict[\"textbody\"] = comment.body\n",
    "        comment_dict[\"username\"] = comment.author\n",
    "        comment_dict[\"depth\"] = comment.depth\n",
    "        comment_dict[\"upvotes\"] = comment.ups\n",
    "\n",
    "        # Only count replies that aren't from the reddit bots\n",
    "        filtered_replies = [r for r in comment.replies if r.author not in ALLOWED_AUTHORS]\n",
    "        comment_dict[\"replies\"] = len(filtered_replies)\n",
    "        \n",
    "        all_comments.append(comment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to simply parse the list of dicts into a dataframe. Everything looks as expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>thread</th>\n",
       "      <th>textbody</th>\n",
       "      <th>username</th>\n",
       "      <th>depth</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>replies</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gq5iprx</th>\n",
       "      <td>reddit.com/r/datascience/comments/lzpbaf/weekl...</td>\n",
       "      <td>07Mar2021-14Mar2021</td>\n",
       "      <td>I’ve found a lot of posts/comments within this...</td>\n",
       "      <td>may4422</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gq4ztgk</th>\n",
       "      <td>reddit.com/r/datascience/comments/lzpbaf/weekl...</td>\n",
       "      <td>07Mar2021-14Mar2021</td>\n",
       "      <td>I'm graduating from University with a Computer...</td>\n",
       "      <td>praventz</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gq68qh7</th>\n",
       "      <td>reddit.com/r/datascience/comments/lzpbaf/weekl...</td>\n",
       "      <td>07Mar2021-14Mar2021</td>\n",
       "      <td>I’m new to Reddit but looking to expand my ski...</td>\n",
       "      <td>No-Half3399</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gq8joip</th>\n",
       "      <td>reddit.com/r/datascience/comments/lzpbaf/weekl...</td>\n",
       "      <td>07Mar2021-14Mar2021</td>\n",
       "      <td>**What to learn after Pandas and Matplotlib? (...</td>\n",
       "      <td>meerkat99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gq8w0yu</th>\n",
       "      <td>reddit.com/r/datascience/comments/lzpbaf/weekl...</td>\n",
       "      <td>07Mar2021-14Mar2021</td>\n",
       "      <td>\\n\\nHello, guys! I'm working as a data person...</td>\n",
       "      <td>AggressivePrune7212</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       url  \\\n",
       "id                                                           \n",
       "gq5iprx  reddit.com/r/datascience/comments/lzpbaf/weekl...   \n",
       "gq4ztgk  reddit.com/r/datascience/comments/lzpbaf/weekl...   \n",
       "gq68qh7  reddit.com/r/datascience/comments/lzpbaf/weekl...   \n",
       "gq8joip  reddit.com/r/datascience/comments/lzpbaf/weekl...   \n",
       "gq8w0yu  reddit.com/r/datascience/comments/lzpbaf/weekl...   \n",
       "\n",
       "                      thread  \\\n",
       "id                             \n",
       "gq5iprx  07Mar2021-14Mar2021   \n",
       "gq4ztgk  07Mar2021-14Mar2021   \n",
       "gq68qh7  07Mar2021-14Mar2021   \n",
       "gq8joip  07Mar2021-14Mar2021   \n",
       "gq8w0yu  07Mar2021-14Mar2021   \n",
       "\n",
       "                                                  textbody  \\\n",
       "id                                                           \n",
       "gq5iprx  I’ve found a lot of posts/comments within this...   \n",
       "gq4ztgk  I'm graduating from University with a Computer...   \n",
       "gq68qh7  I’m new to Reddit but looking to expand my ski...   \n",
       "gq8joip  **What to learn after Pandas and Matplotlib? (...   \n",
       "gq8w0yu   \\n\\nHello, guys! I'm working as a data person...   \n",
       "\n",
       "                    username  depth  upvotes  replies  \n",
       "id                                                     \n",
       "gq5iprx              may4422      0        4        2  \n",
       "gq4ztgk             praventz      0        3        0  \n",
       "gq68qh7          No-Half3399      0        2        1  \n",
       "gq8joip            meerkat99      0        2        1  \n",
       "gq8w0yu  AggressivePrune7212      0        2        2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.DataFrame(all_comments)\n",
    "raw_df = raw_df.set_index('id')\n",
    "raw_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
