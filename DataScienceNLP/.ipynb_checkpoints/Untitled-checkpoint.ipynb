{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised NLP on /r/datascience Comments\n",
    "\n",
    "This is a notebook for performing unsupervised NLP on the comments from the datascience subreddit \"Weekly Entering & Transitioning Thread\"\n",
    "\n",
    "The most current one being:\n",
    "https://www.reddit.com/r/datascience/comments/m4u0uu/weekly_entering_transitioning_thread_14_mar_2021/\n",
    "\n",
    "This notebook covers all steps of analysis:\n",
    "1. Data Collection\n",
    "1. Feature Engineering\n",
    "1. Modelling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping\n",
    "\n",
    "To collect the comments will make use of the reddit praw API, which allows us to perform simple (but adequate) queries and collect posts and comments in a useful object oriented format!\n",
    "\n",
    "As a note, I store reddit IDs and Sectets in a separate yaml file, you will have to make your own if you plan to copy any code snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.1.0 of praw is outdated. Version 7.2.0 was released Wednesday February 24, 2021.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import praw\n",
    "\n",
    "yaml_file = open(\"/Users/harry/scrapeReddit/reddit_keys.yml\")\n",
    "parsed_yaml = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "reddit = praw.Reddit(client_id=parsed_yaml[\"client_id\"],                                                                                                                                                                                          \n",
    "                     client_secret=parsed_yaml[\"client_secret\"],                                                                                                                                                                       \n",
    "                     user_agent=parsed_yaml[\"user_agent\"],                                                                                                                                                                                            \n",
    "                     username=parsed_yaml[\"username\"],                                                                                                                                                                                      \n",
    "                     password=parsed_yaml[\"password\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search the datascience subreddit for posts with both \"weekly\" and \"thread\" in the title, and to only keep posts written by the authors \"datascience-bot\" and \"AutoModerator\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_authors = [\"datascience-bot\", \"AutoModerator\"]\n",
    "all_threads = []\n",
    "for submission in reddit.subreddit(\"datascience\").search(\"weekly+thread\", limit=1000):\n",
    "    if submission.author not in allowed_authors:\n",
    "        continue\n",
    "    all_threads.append(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
